{
  "hash": "44ff0b08627c030263331d8b7167f4e8",
  "result": {
    "engine": "knitr",
    "markdown": "---\nformat:\n  revealjs:\n    height: 900\n    width: 1600\n    logo: \"images/osu.png\"\n    slide-number: true\n    scrollable: true\n---\n\n\n\n## Copula-Based Mixture Transition Distribution Models for Forecasting Skewed and Zero-Inflated Time Series: Methodology and Comparisons with Deep Learning LSTM Networks  \n\n<br>\n\n<br>\n\n<br>\n\n::::: columns\n\n::: column\n\n### Frances Lin\n\nüõ° Dissertation Defense  \n\nü¶´ Oregon State University  \n\nNovember 5, 2025\n\n::: \n\n::: column\n\n###\n\nCo-Advisors: Dr. Lisa Madsen, Dr. Charlotte Wickham\n\nCommittee Members: Dr. James Molyneux, Dr. Claudio Fuentes, Dr. Prasad Tadepalli\n\n::: \n\n::::: \n\n## Motivation  \n\nModeling complex patterns in sequence data is a central task across domains such as energy, insurance, and transportation. \n\n- ‚ö†Ô∏è Real-world time series often show skewness and zero inflation, which can hinder prediction if ignored. \n\n. . .    \n\nRecent AI advances, such as Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks, effectively capture nonlinear and long-range dependence. \n\n. . .    \n\n- ‚ö†Ô∏è A prior work found comparable performance between probabilistic Mixture Transition Distribution (MTD) model and deep learning LSTM for predicting disease spread. \n\n- ‚ö†Ô∏è Claims of LSTM superiority can be misleading when compared to inappropriate benchmarks. \n\n--- \n\n![](images/nasa-1.jpg){.absolute top=0 left=0 width=\"900\" height=\"675\"}\n\n![](images/nasa-2.jpg){.absolute top=0 left=950 width=\"250\" height=\"675\"}\n\n![](images/nasa-3.jpg){.absolute top=0 left=1250 width=\"250\" height=\"675\"}\n\n<div style=\"margin-top: 725px;\">\n¬©Ô∏è NASA Earth Data\nüìç Limon Wind Energy Center, Colorado  \n</div>\n\n## NASA MERRA-2 Data\n\n::: {.panel-tabset}\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\n### windspeeds at 50m above ground\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n\n### windspeeds at 10m above ground\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-5-1.png){width=960}\n:::\n:::\n\n\n\n### windspeeds at 2m above ground\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n\n\n::: \n\n\n\n## Objectives \n\nPart I and II\n\n> Develop the copula-based Gamma Mixture Transition Distribution (Gamma MTD) model and its zero-inflated extension (ZIGamma MTD) to capture nonlinear dependence, skewed distributions, and semicontinuous patterns. \n\n. . .\n\nPart III\n\n> Evaluate the proposed models alongside deep learning approaches, specifically the Long Short-Term Memory (LSTM) networks, demonstrating superior predictive performance and robustness.\n\n## Roadmap \n\nPart I Models for Forecasting Skewed Time Series \n\n- Recap of MTD Models \n\n- Sensitivity Analysis \n\n- Coverage Assessment \n\nPart II Models for Forecasting Zero-Inflated Skewed Time Series\n\n- Introduction\n\n- Background\n\n- Proposed Method\n\n- Simulation Studies\n\n- Prediction\n\n\n## Roadmap \n\nPart III Copula-Based Markov MTD Models vs. Deep Learning LSTM Networks\n\n- Introduction\n\n- Background\n\n- Hyperparameter Tuning, Training, and Metrics \n\n- Simulation Studies \n\n- Data Application\n\n# Part I Models for Forecasting Skewed Time Series {background-color=\"#D73F09\" color=\"white\"} \n\n## Introduction \n\nTime series model captures how past values contribute to current value and uses this information to predict future value.\n\n. . .\n\nThe mixture transition distribution (MTD) models \n\n- Extend the autoregressive (AR) models to accommodate discrete, continuous, and mixed time series.\n\n- Model each conditional distribution as a mixture of transition kernels, with random, stochastic weights.\n\n## Introduction and Objectives \n\nOur work builds upon the architecture of the MTD model introduced by Zheng et al. (2022). \n\n- Includes various applications, such as Gaussian, Poisson, negative binomial, and Lomax regression MTD models, extending beyond linear, Gaussian dynamics. \n\n. . .\n\nHowever, for certain invariant marginal distributions, the transition kernel may either require careful construction or can result in a form that is not explicitly defined or too complex. \n\n. . .\n\n> **Objectives:** Propose to incorporate copulas into the transition kernels to address this limitation.\n\n. . .\n\n> Develop the Gamma MTD model, but the framework is generalizable.\n\n## Background \n\n## Model Framework: DAG; also known as Bayesian network \n\nLet $\\{ X_t: t \\in \\mathbb{N} \\}$ be a time series. Construct the model on a DAG, the joint distribution of $X_1$ to $X_t$ can be factorized into a product of conditional distributions as\n\n\n```{=latex}\n\\begin{equation}\nf(\\textbf{x}) = f(x_1) \\prod_{t=2}^t f(x_t | \\textbf{x}^{t-1}). \\tag{1}\n\\label{eq:joint_distribution}\n\\end{equation}\n```\n\n\n\\scriptsize $f(x_t | \\textbf{x}^{t-1})$ is the conditional probability density function (pdf) of current value $X_t$ given all of its past values $\\textbf{X}^{t-1} = \\textbf{x}^{t-1}$, where $\\textbf{X}^{t-1} = \\{X_i: i \\leq t - 1 \\}$ and $\\textbf{x}^{t-1} = \\{x_i: i \\leq t - 1 \\}$.\n\n. . .\n\n## Model Framework: DAG; also known as Bayesian network \n\nEach conditional in (1) is modeled as a mixture of transition kernels, with mixture weights, for each one of a given number of lags. \n\n. . .\n\n$$\nX_1, X_2, X_3, X_4, X_5, \\ \\ \\ \\ \\  \\ \\ \\ \\ \\ X_6 \n$$\n\n. . .\n\n$$\nX_2, X_3, X_4, X_5, X_6, \\ \\ \\ \\ \\  \\ \\ \\ \\ \\ X_7 \n$$\n\n. . .\n\n$$\n\\cdots\n$$\n\n$$\nX_{t-5}, X_{t-4}, X_{t-3}, X_{t-2}, X_{t-1},  \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ X_t \n$$\n\n\n## Model Framework: Transition kernels & mixture weights \n\nFor $t > L$, the MTD model specifies the conditional distribution of $X_t$ given $\\textbf{X}^{t-1} = \\textbf{x}^{t-1}$ as \n\n\n```{=latex}\n\\begin{equation}\nf(x_t | \\textbf{x}^{t-1}) = \\sum_{l=1}^L w_l f_l (x_t | x_{t-l}). \\tag{2}\n\\label{eq:cond_distribution}\n\\end{equation}\n```\n\n\n\\scriptsize $f_l (x_t | x_{t-l})$ is the conditional pdf of $X_t$ with respect to the $l$th transition kernel given that ${X}_{t-l} = {x}_{t-l}$. $w_l$ are weight parameters, where $w_l \\geq 0$ such that $\\sum_{l=1}^L w_l = 1$.\n\n. . .\n\n\\normalsize\n\nThere are two components in (2):\n\n  - Transition kernel, $f_l$, captures the influence of the $l$th lag value on the current value.  \n  \n  - Weight parameter, $w_l$, determines the relative contribution of that influence. \n\n--- \n\n![](images/financial.jpg){.absolute top=0 left=0 width=\"1200\" height=\"675\"}\n\n<div style=\"margin-top: 725px;\">\n¬©Ô∏è Yuvraj Deshmukh\n‚è≠Ô∏è Copula\n</div>\n\n## Copula \n\nCopula is widely used for dependence modeling.\n\n  - Is applied in quantitative finance, reliability engineering, hydrology, etc.\n\n  - Consists of families of copula, constituting a substantial research area.\n\n. . .\n\nCopula is a multivariate cumulative distribution function (cdf) where its marginal distribution of each random variables is $Unif(0, 1)$. \n\n. . .\n\nUsing copula, any joint distribution, $F$, can be decomposed into two parts: the copula, $C$, and the marginal distributions, $F_j$, $j = 1,..., p$.\n\n- Rooted in Sklar‚Äôs theorem. \n  \n\n## Existing Method to Proposed Method \n\nThe bivariate distribution approach, for example, identifies a bivariate distribution of $(U_l, V_l)$ such that the marginal densities, $f_{U_l}$ and $f_{V_l}$, are equal to a pre-specified stationary marginal density $f_X$ for all $l$ transition kernels. \n\n- Based on Proposition 1 of Zheng et al. (2022).\n\n. . .\n\nThis is facilitated by the use of a copula, which separates the marginal behavior of the random variables from their dependence structure. \n\n$$\n\\textbf{transition kernel} \\longleftarrow \\textbf{copula} \\times \\textbf{marginal} \n$$\n$$\n\\ f_l (x_t | x_{t-l}) \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ c_l (x_t, x_{t-l}) \\ \\ \\ \\ f_X (x_t) \n$$\n\n## Proposed Method  \n\nReplace $f_{U_l}$ and $f_{V_l}$ with a pre-specified stationary marginal density, $f_X$, for every $x_t$ and for all $l$. For $t > L$, the proposed copula-based MTD model specifies the conditional distribution as\n\n\n```{=latex}\n\\begin{equation}\nf(x_t | \\textbf{x}^{t-1}) = \\sum_{l=1}^L w_l c_l (x_t, x_{t-l}) f_X(x_t). \\tag{3}\n\\label{eq:cond_distribution_copula}\n\\end{equation}\n```\n\n\n\\scriptsize $c_l (x_t, x_{t-l})$ is the copula density evaluated at $x_t$ and $x_{t-l}$, and $f_X(x_t)$ is the stationary marginal density evaluated at $x_t$. \n\n. . .\n\n\\normalsize\n\nCompared to (2), the transition kernel, $f_l$, is now replaced by two components: \n\n  - Copula density, $c_l$, captures and controls the strength of the dependence through a dependence parameter.\n  \n  - Stationary marginal density, $f_X$, describes the marginal behavior through distribution parameters.\n\n## Background: Bayesian Implementation  \n\nEarlier MTD models were built through frequentist approaches. \n\nEstimation and prediction in the MTD model by Zheng et al. (2022) is constructed with Bayesian methodologies.\n\n  - Our proposed copula-based MTD model builds upon this model version. \n  \n  - We consider the Gaussian copula with Gamma marginals, i.e., Gamma MTD model. \n\n## Background: Bayesian Implementation  \n\nInference is facilitated through a set of latent variables ${\\{Z_t\\}}_{t=L+1}^n$. $Z_t = l$ indicates which $l$th kernel or component the data belongs to. \n\nThe posterior distribution of the parameters, based on the conditional likelihood, is\n\n\n```{=latex} \n\\begin{equation}\n\\begin{split}\np(\\boldsymbol{w}, \\boldsymbol{\\theta}, {\\{z_t\\}}_{t=L+1}^n | D_n) \\propto \\pi_w(\\boldsymbol{w}) \\prod_{l=1}^L \\pi_l(\\boldsymbol{\\theta}_l) \\\\ \n\\prod_{t=L+1}^n \\Biggl\\{ f_{z_t} (x_t | x_{t-z_t}, \\boldsymbol{\\theta}_{z_t}) \\sum_{l=1}^L w_l \\delta_l(z_t) \\Biggl\\}.\n\\end{split}\n\\end{equation}\n```\n\n\n\\scriptsize $\\boldsymbol{\\theta}$ collects parameters for the transition kernel. $D_n = {\\{x_t\\}}_{t=L+1}^n$ is the data.\n\n. . .\n\n\\normalsize \n\nWith priors specifications, the full simulation-based Bayesian estimation and prediction can be achieved using Markov chain Monte Carlo (MCMC) algorithms. \n\n## Simulation Studies  \n\nWe have assessed accuracy and performance of the proposed model. \n\n- Convergence Diagnostics ($\\boldsymbol{w}$, $\\boldsymbol{\\rho}$, $\\alpha$, $\\beta$)\n\n- Weight and Dependence Parameters for Copula ($\\boldsymbol{w}$, $\\boldsymbol{\\rho}$)\n\n- Parameters for Marginal Distribution ($\\alpha$, $\\beta$)\n\n. . .\n\nSimulation studies demonstrate promising results across various scenarios. \n\n- Scenario 1 and 2: Default setup; Compatible $\\boldsymbol{w}$ and $\\boldsymbol{\\rho}$\n\n- Scenario 1.3 and 1.4: Incompatible $\\boldsymbol{w}$ and $\\boldsymbol{\\rho}$\n\n- Scenario 1.5 and 1.6: Compatible $\\boldsymbol{w}$ and $\\boldsymbol{\\rho}$; Rarely observable patterns\n\n- Scenario 3-6: Usual case for gamma marginals\n\n- Scenario 7-9:Unusual case involving high skewness\n\n## What's New  \n\nSince the Preliminary Exam, we have also conducted:\n\n- Sensitivity Analysis\n\n- Coverage Assessment\n\n. . .\n\nResults appear reasonable, and the estimates are consistent with the true values, indicating that the model is robust to the choice of prior. \n\nMost parameters achieve full coverage, indicating that the posterior intervals reliably capture the true parameter values.\n\n# Part II Models for Forecasting Zero-Inflated Skewed Time Series {background-color=\"#D73F09\" color=\"white\"}\n\n## Introduction  \n\nZero-inflated data are characterized by an excess of zero values and  frequently appear in domains such as healthcare, insurance, environment, and transportation. \n\nExamples include \n\n- medical costs, \n\n- insurance claims, \n\n- precipitation amounts, and \n\n- safety measures.\n\nIf left unaddressed, zero-inflation undermines model robustness and weakens inference.\n\n## Introduction and Objectives \n\nIn Part I, we propose the copula-based Gamma MTD model, which enables flexible dependence modeling and accommodates arbitrary continuous marginals. \n\nHowever, \n\n- it remains limited in handling excessive zeros commonly observed in real-world continuous data. \n\n- Copula-based approaches face identifiability issues when modeling discrete or mixed marginals.\n\n. . .\n\n> **Objectives:** Propose reconstructing the marginal distribution to account for zero-inflation. \n\n. . .\n\n> Develop the ZIGamma MTD model, but the framework is generalizable.\n\n## Background\n\n## Proposed Method  \n\nTo construct zero-inflated Gamma for the marginal distribution, \n\n- The Gamma distribution is first reparametrized in terms of the mean, $\\mu$, and the scale parameter, $\\beta$. \n\n- Zero values are then replaced with non-zero values drawn from a uniform distribution. \n\n. . .\n\nSpecifically,\n\n\n```{=latex} \n\\begin{equation}\n0 \\leftarrow U_i, \\tag{4}\n\\end{equation}\n```\n\n\nwhere $U_i$ follows a continuous uniform distribution on $(0, \\epsilon)$ with $\\epsilon$ is a data-driven paramater representing the smallest observed non-zero values. \n\n## Proposed Method  \n\nThe resulting distribution, denoted as $ZIGamma(\\mu, \\beta, P, \\epsilon)$, is expressed as:\n\n\n```{=latex} \n\\begin{equation}\nf(x) = \n\\begin{cases} \nUnif(0, \\epsilon) & \\text{with probability } P \\\\\nShiftedGamma(\\mu, \\beta; \\epsilon) & \\text{with probability } 1-P, \n\\end{cases}, \\tag{5}\n\\end{equation}\n```\n\n\nwhere $\\mu$ denotes the mean and $\\beta$ the scale parameter of the shifted Gamma distribution, $P \\in [0, 1]$ the zero-inflated probability, and $\\epsilon > 0$ the threshold parameter. \n\n. . .\n\nIn (5), there are two parts: \n\n- We have already discussed the uniform distribution. \n\n- The shifted Gamma distribution, $ShiftedGamma(\\mu, \\beta; \\epsilon)$, is a standard Gamma distribution with mean $\\mu$ and scale $\\beta$ that is shifted to the right by $\\epsilon$, with the support $[\\epsilon, \\infty)$. \n\n## dzig   \n\n::: {.panel-tabset}\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\n### $P = 0.1$ $\\epsilon = 0.1$\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-9-1.png){width=960}\n:::\n:::\n\n\n\n### $P = 0.1$ $\\epsilon = 0.4$\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-10-1.png){width=960}\n:::\n:::\n\n\n\n### $P = 0.5$ $\\epsilon = 0.1$\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-11-1.png){width=960}\n:::\n:::\n\n\n\n### $P = 0.5$ $\\epsilon = 0.4$\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-12-1.png){width=960}\n:::\n:::\n\n\n\n### $P = 0.7$ $\\epsilon = 0.1$\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-13-1.png){width=960}\n:::\n:::\n\n\n\n### $P = 0.7$ $\\epsilon = 0.4$\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-14-1.png){width=960}\n:::\n:::\n\n\n\n:::\n\n## pzig   \n\n::: {.panel-tabset}\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\n### $P = 0.1$ $\\epsilon = 0.1$\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-17-1.png){width=960}\n:::\n:::\n\n\n\n### $P = 0.1$ $\\epsilon = 0.4$\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-18-1.png){width=960}\n:::\n:::\n\n\n\n### $P = 0.5$ $\\epsilon = 0.1$\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-19-1.png){width=960}\n:::\n:::\n\n\n\n### $P = 0.5$ $\\epsilon = 0.4$\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-20-1.png){width=960}\n:::\n:::\n\n\n\n### $P = 0.7$ $\\epsilon = 0.1$\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-21-1.png){width=960}\n:::\n:::\n\n\n\n### $P = 0.7$ $\\epsilon = 0.4$\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-22-1.png){width=960}\n:::\n:::\n\n\n\n:::\n\n## Simulation Setting   \n\nSimulated data: \n\n- With weight $\\boldsymbol{w}$, dependence for Gaussian copula $\\boldsymbol{\\rho}$, mean $\\mu$, scale $\\beta$, zero-inflated probability $P$, and threshold parameter $\\epsilon$, we generate $n = 2000$ observations from the copula-based ZIGamma MTD model.\n\nModel fitting: \n\n- Set the order $L = 5$ and consider the Gaussian copula with Gamma marginals.\n\nMCMC setting: \n\n- Run the Gibbs sampler for $165, 000$ iterations, discard the first $5000$ iterations as burn-in, and collect samples every $20$ iterations.\n\n- Run four MCMC chains with $8000$ iterations each for all of the following scenarios. \n\n## Simulation Studies   \n\nWe have assessed accuracy and performance of the proposed model.\n\n- Convergence Diagnostics ($\\boldsymbol{w}$, $\\boldsymbol{\\rho}$, $\\mu$, $\\beta$, $P$, $\\epsilon$)\n\n- Weight and Dependence Parameters for Copula ($\\boldsymbol{w}$, $\\boldsymbol{\\rho}$)\n\n- Parameters for Marginal Distribution ($\\mu$, $\\beta$, $P$, $\\epsilon$)\n\nSimulation studies demonstrate promising results across various scenarios. \n\n- Scenario 1 and 2: Default setup; Compatible $\\boldsymbol{w}$ and $\\boldsymbol{\\rho}$\n\n- Scenario 3-6: Usual case for zero-inflated gamma marginals\n\n- Scenario 7-9: Unusual case involving high skewness\n\n## Simulation Studies   \n\nIn all nine scenarios, we vary $P$ and $\\epsilon$, resulting in six cases per scenario: \n\n- $P = 0.1$, $\\epsilon = 0.1$\n\n- $P = 0.1$, $\\epsilon = 0.4$\n\n- $P = 0.5$, $\\epsilon = 0.1$\n\n- $P = 0.5$, $\\epsilon = 0.4$\n\n- $P = 0.7$, $\\epsilon = 0.1$\n\n- $P = 0.7$, $\\epsilon = 0.4$\n\nFor brevity, we present Scenario 1 only.\n\n## Simulation Results   \n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\n::: {.panel-tabset}\n\n### $w$ \n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|.             |Mean (SD)       |R (Upper CI) | Naive SE| Time-series SE|\n|:-------------|:---------------|:------------|--------:|--------------:|\n|$w_1 = 0.636$ |0.6395 (0.0425) |1 (1)        |    2e-04|         0.0003|\n|$w_2 = 0.234$ |0.1905 (0.0636) |1.01 (1.01)  |    4e-04|         0.0013|\n|$w_3 = 0.086$ |0.1315 (0.0739) |1 (1)        |    4e-04|         0.0021|\n|$w_4 = 0.032$ |0.0346 (0.0529) |1.01 (1.03)  |    3e-04|         0.0017|\n|$w_5 = 0.012$ |0.0039 (0.0171) |1 (1)        |    1e-04|         0.0004|\n\n\n:::\n:::\n\n\n\n### $\\rho$\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|.                |Mean (SD)        |R (Upper CI) | Naive SE| Time-series SE|\n|:----------------|:----------------|:------------|--------:|--------------:|\n|$\\rho_1 = 0.700$ |0.6847 (0.0274)  |1 (1)        |   0.0002|         0.0002|\n|$\\rho_2 = 0.500$ |0.606 (0.1426)   |1.01 (1.01)  |   0.0008|         0.0027|\n|$\\rho_3 = 0.300$ |0.1168 (0.2389)  |1 (1)        |   0.0013|         0.0018|\n|$\\rho_4 = 0.100$ |0.0147 (0.4675)  |1 (1)        |   0.0026|         0.0027|\n|$\\rho_5 = 0.100$ |-0.0046 (0.5659) |1 (1)        |   0.0032|         0.0032|\n\n\n:::\n:::\n\n\n\n::: \n\n## Simulation Results   \n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n\n\n::: {.panel-tabset}\n\n### $P = 0.1$ $\\epsilon = 0.1$\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|.          |Mean (SD)       |R (Upper CI) | Naive SE| Time-series SE|\n|:----------|:---------------|:------------|--------:|--------------:|\n|$\\mu$      |7.35 (0.1132)   |1 (1)        |    6e-04|          6e-04|\n|$\\beta$    |1.0082 (0.0433) |1 (1)        |    2e-04|          2e-04|\n|$P$        |0.0769 (0.0085) |1 (1)        |    0e+00|          0e+00|\n|$\\epsilon$ |0.1 (7e-04)     |1 (1)        |    0e+00|          0e+00|\n\n\n:::\n:::\n\n\n\n### $P = 0.1$ $\\epsilon = 0.4$\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|.          |Mean (SD)       |R (Upper CI) | Naive SE| Time-series SE|\n|:----------|:---------------|:------------|--------:|--------------:|\n|$\\mu$      |7.1454 (0.12)   |1 (1)        |    7e-04|          7e-04|\n|$\\beta$    |1.0994 (0.0472) |1 (1)        |    3e-04|          3e-04|\n|$P$        |0.1091 (0.0103) |1 (1)        |    1e-04|          1e-04|\n|$\\epsilon$ |0.4017 (0.0019) |1 (1)        |    0e+00|          0e+00|\n\n\n:::\n:::\n\n\n\n### $P = 0.5$ $\\epsilon = 0.1$\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|.          |Mean (SD)       |R (Upper CI) | Naive SE| Time-series SE|\n|:----------|:---------------|:------------|--------:|--------------:|\n|$\\mu$      |6.9447 (0.1207) |1 (1)        |    7e-04|          7e-04|\n|$\\beta$    |1.0659 (0.0542) |1 (1)        |    3e-04|          3e-04|\n|$P$        |0.5248 (0.0172) |1 (1)        |    1e-04|          1e-04|\n|$\\epsilon$ |0.1001 (1e-04)  |1 (1)        |    0e+00|          0e+00|\n\n\n:::\n:::\n\n\n\n### $P = 0.5$ $\\epsilon = 0.4$\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|.          |Mean (SD)       |R (Upper CI) | Naive SE| Time-series SE|\n|:----------|:---------------|:------------|--------:|--------------:|\n|$\\mu$      |6.8454 (0.1154) |1 (1)        |    6e-04|          6e-04|\n|$\\beta$    |1.0086 (0.0512) |1 (1)        |    3e-04|          3e-04|\n|$P$        |0.5064 (0.0173) |1 (1)        |    1e-04|          1e-04|\n|$\\epsilon$ |0.4 (4e-04)     |1 (1)        |    0e+00|          0e+00|\n\n\n:::\n:::\n\n\n\n### $P = 0.7$ $\\epsilon = 0.1$\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|.          |Mean (SD)       |R (Upper CI) | Naive SE| Time-series SE|\n|:----------|:---------------|:------------|--------:|--------------:|\n|$\\mu$      |6.988 (0.1303)  |1 (1)        |    7e-04|          7e-04|\n|$\\beta$    |0.9593 (0.0594) |1 (1)        |    3e-04|          3e-04|\n|$P$        |0.6879 (0.016)  |1 (1)        |    1e-04|          1e-04|\n|$\\epsilon$ |0.0999 (1e-04)  |1 (1)        |    0e+00|          0e+00|\n\n\n:::\n:::\n\n\n\n### $P = 0.7$ $\\epsilon = 0.4$\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|.          |Mean (SD)       |R (Upper CI) | Naive SE| Time-series SE|\n|:----------|:---------------|:------------|--------:|--------------:|\n|$\\mu$      |6.8482 (0.1373) |1 (1)        |    8e-04|          8e-04|\n|$\\beta$    |1.0506 (0.0665) |1 (1)        |    4e-04|          4e-04|\n|$P$        |0.7048 (0.0154) |1 (1)        |    1e-04|          1e-04|\n|$\\epsilon$ |0.4002 (3e-04)  |1 (1)        |    0e+00|          0e+00|\n\n\n:::\n:::\n\n\n\n:::\n\n## Coverage Assessment\n\nAll nine scenarios were analyzed using a single replicate. \n\n- Recall that we have six cases per scenario.\n\n. . .\n\nScenarios 1 and 2 were further evaluated with $10$ replicates to assess coverage and robustness. \n\n- The overall coverage is the proportion of replicates for which the true value is contained within the interval.\n\n. . .\n\nMost parameters achieve full coverage, with a few slightly below $1$, indicating that the posterior intervals reliably capture the true parameter values.\n\n\n## Prediction   \n\n::::: columns\n\n::: column\n\n### \n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n\n\n|         |Coverage |Below                                                |Above                                                |\n|:--------|:--------|:----------------------------------------------------|:----------------------------------------------------|\n|P01Eps01 |0.9549   |0.6944                                               |<span style=\" font-weight: bold;    \" >0.9751</span> |\n|P01Eps04 |0.9148   |0.3973                                               |<span style=\" font-weight: bold;    \" >0.9786</span> |\n|P05Eps01 |0.9278   |<span style=\" font-weight: bold;    \" >0.9876</span> |0.8615                                               |\n|P05Eps04 |0.9484   |<span style=\" font-weight: bold;    \" >0.9681</span> |0.9285                                               |\n|P07Eps01 |0.8677   |<span style=\" font-weight: bold;    \" >0.9943</span> |0.5726                                               |\n|P07Eps04 |0.9298   |<span style=\" font-weight: bold;    \" >0.9888</span> |0.7828                                               |\n\n\n:::\n:::\n\n\n\n::: \n\n::: column\n\n### \n\n- When the zero-inflated probability is low (e.g., $P = 0.1$), the empirical coverage **above** (i.e., the coverage for data greater than $\\epsilon$) is a more informative metric for assessing predictive performance. \n\n- As $P$ increases (e.g., $P = 0.5$, $0.7$), the empirical coverage **below** (i.e., the coverage for data less than or equal to $\\epsilon$) becomes increasingly dominant. \n\n::: \n\n::::: \n\n## Prediction   \n\n::: {.panel-tabset}\n\n### $P = 0.1$ $\\epsilon = 0.1$\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-46-1.png){width=960}\n:::\n:::\n\n\n\n### $P = 0.1$ $\\epsilon = 0.4$\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-47-1.png){width=960}\n:::\n:::\n\n\n\n### $P = 0.5$ $\\epsilon = 0.1$\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-48-1.png){width=960}\n:::\n:::\n\n\n\n### $P = 0.5$ $\\epsilon = 0.4$\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-49-1.png){width=960}\n:::\n:::\n\n\n\n### $P = 0.7$ $\\epsilon = 0.1$\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-50-1.png){width=960}\n:::\n:::\n\n\n\n### $P = 0.7$ $\\epsilon = 0.4$\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-51-1.png){width=960}\n:::\n:::\n\n\n\n::: \n\n# Part III Copula-Based Markov MTD Models vs. Deep Learning LSTM Networks {background-color=\"#D73F09\" color=\"white\"} \n\n## Introduction   \n\nRecurrent Neural Networks (RNNs), and their variants, Long Short-Term Memory (LSTMs), are widely used for modeling sequence data because of their ability to capture both short- and long-term dependencies.\n\n. . .\n\nBeyond natural language processing (NLP), RNNs and LSTMs have also shown effective in time series forecasting and have been employed for applications including\n\n- financial market prediction, \n\n- energy forecasting,\n\n- weather and climate modeling, and\n\n- epidemiological trend analysis.\n\n## Introduction and Objectives  \n\nHowever, \n\n- a prior study found comparable performance between the MTD model and the LSTM network for predicting disease spread.\n\n- Previous studies comparing LSTMs to traditional models such as ARIMA often claim LSTM superiority, a conclusion that can be misleading when the benchmarks chosen are inappropriate.\n\n. . .\n\n> **Objectives:** Systematically evaluate LSTM and MTD models to ensure a fair and balanced comparison of their performance and robustness. \n\n. . .\n\n> Demonstrate that our proposed MTDs outperform LSTMs in accuracy, but at a higher computational cost and the need for careful design. \n\n## Background   \n\n## Experimental Setup   \n\n## Simulation Studies   \n\n## Simulation Results for Gamma Scenarios\n\n## Simulation Results for ZIGamma Scenarios\n\n## Data Application   \n\n## Data Application \n\n## Data Application \n\n::: {.panel-tabset}\n\n### windspeeds at 50m above ground\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-53-1.png){width=960}\n:::\n:::\n\n\n\n### windspeeds at 10m above ground\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-54-1.png){width=960}\n:::\n:::\n\n\n\n### windspeeds at 2m above ground\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-revealjs/unnamed-chunk-55-1.png){width=960}\n:::\n:::\n\n\n\n::: \n\n## Conclusion \n\n## Future Work\n\n## Practical Implications\n\n# Thank you!\n\n## Acknowledgement\n\n## References \n\n# Supplement",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}